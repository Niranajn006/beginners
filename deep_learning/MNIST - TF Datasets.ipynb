{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "digits = load_digits(return_X_y=True)\n",
    "# split into train and validation sets\n",
    "train_images = digits[0][:int(len(digits[0]) * 0.8)].reshape([1437,8,8,1])\n",
    "train_labels = digits[1][:int(len(digits[0]) * 0.8)]\n",
    "valid_images = digits[0][int(len(digits[0]) * 0.8):].reshape([360,8,8,1])\n",
    "valid_labels = digits[1][int(len(digits[0]) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training datasets\n",
    "dx_train = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "# apply a one-hot transformation to each label for use in the neural network\n",
    "dy_train = tf.data.Dataset.from_tensor_slices(train_labels).map(lambda z: tf.one_hot(z, 10))\n",
    "# zip the x and y training data together and shuffle, batch etc.\n",
    "train_dataset = tf.data.Dataset.zip((dx_train, dy_train)).shuffle(500).repeat().batch(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same operations for the validation set\n",
    "dx_valid = tf.data.Dataset.from_tensor_slices(valid_images)\n",
    "dy_valid = tf.data.Dataset.from_tensor_slices(valid_labels).map(lambda z: tf.one_hot(z, 10))\n",
    "valid_dataset = tf.data.Dataset.zip((dx_valid, dy_valid)).shuffle(500).repeat().batch(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create general iterator\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datasets that we can initialize separately, but using the same structure via the common iterator\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "validation_init_op = iterator.make_initializer(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(in_data):\n",
    "    bn = in_data# tf.layers.batch_normalization(in_data)\n",
    "    fc1 = tf.layers.conv2d(bn, 4, 3)\n",
    "    fc2 = tf.layers.conv2d(fc1, 4, 3)\n",
    "    fc2 = tf.layers.conv2d(fc2, 4, 3)\n",
    "    fc3 = tf.contrib.layers.flatten(fc2)\n",
    "    #fc2 = tf.layers.dropout(fc2)\n",
    "    fc4 = tf.layers.dense(fc3, 10)\n",
    "    return fc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_7/BiasAdd:0' shape=(?, 10) dtype=float64>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the neural network model\n",
    "logits = nn_model(next_element[0])\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the optimizer and loss\n",
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=next_element[1], logits=logits))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "# get accuracy\n",
    "prediction = tf.argmax(logits, 1)\n",
    "equality = tf.equal(prediction, tf.argmax(next_element[1], 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 266.802, training accuracy: 0.00%\n",
      "Epoch: 1000, loss: 9.332, training accuracy: 90.00%\n",
      "Epoch: 2000, loss: 0.415, training accuracy: 100.00%\n",
      "Epoch: 3000, loss: 0.453, training accuracy: 100.00%\n",
      "Epoch: 4000, loss: 2.478, training accuracy: 96.67%\n",
      "Epoch: 5000, loss: 0.030, training accuracy: 100.00%\n",
      "Epoch: 6000, loss: 0.128, training accuracy: 100.00%\n",
      "Epoch: 7000, loss: 2.102, training accuracy: 96.67%\n",
      "Epoch: 8000, loss: 1.320, training accuracy: 100.00%\n",
      "Epoch: 9000, loss: 0.079, training accuracy: 100.00%\n",
      "Average validation set accuracy over 100 iterations is 90.93%\n"
     ]
    }
   ],
   "source": [
    "# run the training\n",
    "epochs = 10000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    sess.run(training_init_op)\n",
    "    for i in range(epochs):\n",
    "        l, _, acc = sess.run([loss, optimizer, accuracy])\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i, l, acc * 100))\n",
    "    # now setup the validation run\n",
    "    valid_iters = 100\n",
    "    # re-initialize the iterator, but this time with validation data\n",
    "    sess.run(validation_init_op)\n",
    "    avg_acc = 0\n",
    "    for i in range(valid_iters):\n",
    "        acc = sess.run([accuracy])\n",
    "        avg_acc += acc[0]\n",
    "    print(\"Average validation set accuracy over {} iterations is {:.2f}%\".format(valid_iters, (avg_acc / valid_iters) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
